{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 4.3 of lab1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create time series dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tools import mackey_glass_time_series\n",
    "\n",
    "steps = np.arange(301, 1501)\n",
    "x = mackey_glass_time_series(np.max(steps)+5)\n",
    "input = np.array([[x[t-21], x[t-16], x[t-11], x[t-6], x[t-1]] for t in steps])\n",
    "output = np.array([x[t+4] for t in steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=steps+5, y=output)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Mackey-Glass value\")\n",
    "plt.savefig(\"imgs/time_series.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = input[:-400]\n",
    "X_val = input[-400:-200]\n",
    "X_test = input[-200:]\n",
    "\n",
    "y_train = output[:-400]\n",
    "y_val = output[-400:-200]\n",
    "y_test = output[-200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation subset will be determined through the cross validation scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from tools import TimeSeriesMLP\n",
    "import pandas as pd\n",
    "\n",
    "def parameter_search(X_train, y_train, X_val, y_val, X_test, y_test, layers_config=None, early_stopping=True, n_epochs=500, lambdas=None):\n",
    "    histories = {}\n",
    "\n",
    "    lc = tqdm(layers_config if lambdas is  None else lambdas)\n",
    "    for item in lc:\n",
    "        lc.set_description_str(f\"Evaluating {item}...\")\n",
    "\n",
    "        history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"best_loss\": [],\n",
    "        \"epoch\": [],\n",
    "    }\n",
    "        for _ in tqdm(range(10), leave=False):\n",
    "            if lambdas is None:\n",
    "                model = TimeSeriesMLP(hidden_nodes=item, early_stopping=early_stopping, n_epochs=n_epochs) \n",
    "            else:\n",
    "                model = TimeSeriesMLP(hidden_nodes=layers_config, lmbda=item, early_stopping=False, n_epochs=n_epochs)\n",
    "            h = model.fit(X_train, y_train, X_val, y_val)\n",
    "            history[\"train_loss\"] += h[\"loss\"]\n",
    "            history[\"val_loss\"] += h[\"val_loss\"]\n",
    "            history[\"test_loss\"] += [model.evaluate(X_test, y_test)] * len(h[\"loss\"])\n",
    "            history[\"best_loss\"] += [h[\"val_loss\"][-1]] * len(h[\"loss\"])\n",
    "            history[\"epoch\"] += (np.arange(len(h[\"loss\"])) + 1).tolist()\n",
    "\n",
    "        history = pd.DataFrame(history)\n",
    "        history = history.groupby(\"epoch\").agg([\"mean\", \"std\"])\n",
    "        histories[item] = history.reset_index().to_dict(\"list\")\n",
    "\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import plot_training_histories\n",
    "from itertools import product\n",
    "\n",
    "from warnings import filterwarnings\n",
    "import pandas as pd\n",
    "\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "histories = {}\n",
    "layers_config = list(product([3, 4, 5], [2, 4, 6]))\n",
    "\n",
    "histories = parameter_search(X_train, y_train, X_val, y_val, X_test, y_test, layers_config=layers_config)\n",
    "\n",
    "fig, _ = plot_training_histories(histories)\n",
    "fig.savefig(\"imgs/layers_selection.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_errors = {\n",
    "    config: (history[('best_loss', 'mean')][-1], history[('best_loss', 'std')][-1])\n",
    "    for config, history in histories.items()\n",
    "}\n",
    "\n",
    "ranked_by_final = sorted(\n",
    "    final_val_errors.items(),\n",
    "    key=lambda x: x[1][0],\n",
    ")\n",
    "\n",
    "print(\"Rankings by final validation error:\")\n",
    "for i, (config, error) in enumerate(ranked_by_final, 1):\n",
    "    print(f\"{i}. Architecture {config}: {error[0]:.4f} (std = {error[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rankings by final validation error:\n",
    "1. Architecture (4, 4): 0.0012 (std = 0.0004)\n",
    "2. Architecture (4, 2): 0.0012 (std = 0.0003)\n",
    "3. Architecture (3, 6): 0.0012 (std = 0.0006)\n",
    "4. Architecture (5, 6): 0.0013 (std = 0.0007)\n",
    "5. Architecture (5, 2): 0.0014 (std = 0.0002)\n",
    "6. Architecture (5, 4): 0.0014 (std = 0.0008)\n",
    "7. Architecture (3, 4): 0.0017 (std = 0.0004)\n",
    "8. Architecture (4, 6): 0.0018 (std = 0.0010)\n",
    "9. Architecture (3, 2): 0.0019 (std = 0.0009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test = (histories[ranked_by_final[0][0]][(\"test_loss\", \"mean\")][-1], histories[ranked_by_final[0][0]][(\"test_loss\", \"std\")][-1])\n",
    "worst_test = (histories[ranked_by_final[-1][0]][(\"test_loss\", \"mean\")][-1], histories[ranked_by_final[-1][0]][(\"test_loss\", \"std\")][-1])\n",
    "\n",
    "print(f\"Best model performance on test set: {best_test[0]:.4f} (std = {best_test[1]:.4f})\")\n",
    "print(f\"Worst model performance on test set: {worst_test[0]:.4f} (std = {worst_test[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model performance on test set: 0.0009518225560896099\n",
    "\n",
    "Worst model performance on test set: 0.0011794989695772529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = TimeSeriesMLP(hidden_nodes=ranked_by_final[0][0])\n",
    "best_model.fit(X_train, y_train, X_val, y_val)\n",
    "worst_model = TimeSeriesMLP(hidden_nodes=ranked_by_final[-1][0])\n",
    "worst_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "data = {\n",
    "    \"t\": steps[-200:]+5,\n",
    "    \"Truth\": y_test,\n",
    "    \"Best Model\": best_model.predict(X_test).flatten(),\n",
    "    \"Worst Model\":worst_model.predict(X_test).flatten()\n",
    "}\n",
    "data = pd.DataFrame(data)\n",
    "data = pd.melt(data, [\"t\"])\n",
    "data.columns = [\"t\", \"Model\", \"Value\"]\n",
    "\n",
    "sns.lineplot(data, x=\"t\", y=\"Value\", hue=\"Model\")\n",
    "\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"imgs/time_series_best_vs_worst.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [0.05, 0.15]\n",
    "\n",
    "noised_inputs = []\n",
    "noised_outputs = []\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fig.suptitle(\"Noisy Time Series given a Standard Deviation\")\n",
    "\n",
    "for sigma, ax in zip(sigmas, axs):\n",
    "    length = np.max(steps)+5\n",
    "    x = mackey_glass_time_series(length) + np.random.normal(0, sigma, length)\n",
    "    input = np.array([[x[t-21], x[t-16], x[t-11], x[t-6], x[t-1]] for t in steps])\n",
    "    output = np.array([x[t+4] for t in steps])\n",
    "\n",
    "    noised_inputs.append(input)\n",
    "    noised_outputs.append(output)\n",
    "\n",
    "    sns.lineplot(x=steps+5, y=output, ax=ax)\n",
    "\n",
    "    ax.set_title(f\"$\\\\sigma = {sigma}$\")\n",
    "    ax.set_xlabel(\"t\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"imgs/time_series_noise.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "layers_config = list(product([4], [3, 6, 9]))\n",
    "sigma_histories = {}\n",
    "\n",
    "iterator = tqdm(sigmas)\n",
    "\n",
    "for sigma in iterator:\n",
    "    iterator.set_description(f\"Running with sigma = {sigma}\")\n",
    "\n",
    "    Xn_train = X_train + np.random.normal(0, sigma, X_train.shape)\n",
    "    yn_train = y_train + np.random.normal(0, sigma, y_train.shape)\n",
    "\n",
    "    sigma_histories[sigma] = parameter_search(\n",
    "        Xn_train,\n",
    "        yn_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        layers_config=layers_config,\n",
    "        early_stopping=False,\n",
    "        n_epochs=200\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import plot_training_histories\n",
    "\n",
    "for sigma, histories in sigma_histories.items():\n",
    "    fig, ax = plot_training_histories(histories)\n",
    "    plt.title(f\"Training History for $\\\\sigma = {sigma}$\")\n",
    "    plt.savefig(f\"imgs/layers_selection_{sigma}_noisy.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configs = {0.05: (4, 6), 0.15: (4, 9)}\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "fig.suptitle(\"Actual vs Predicted Values\")\n",
    "\n",
    "for (sigma, config), ax in zip(best_configs.items(), axs):\n",
    "    model = TimeSeriesMLP(\n",
    "        hidden_nodes=config, n_epochs=200, early_stopping=False, lmbda=0\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train + np.random.normal(loc=0, scale=sigma, size=X_train.shape),\n",
    "        y_train + np.random.normal(loc=0, scale=sigma, size=y_train.shape),\n",
    "        X_val,\n",
    "        y_val,\n",
    "    )\n",
    "    data = {\n",
    "        \"t\": steps[-200:] + 5,\n",
    "        \"Truth\": y_test,\n",
    "        f\"{config}\": model.predict(X_test).flatten(),\n",
    "    }\n",
    "    data = pd.DataFrame(data)\n",
    "    data = pd.melt(data, [\"t\"])\n",
    "    data.columns = [\"t\", \"Model\", \"Value\"]\n",
    "\n",
    "    ax = sns.lineplot(data, x=\"t\", y=\"Value\", hue=\"Model\", ax=ax)\n",
    "\n",
    "    ax.set_title(f\"$\\\\sigma = {sigma}$\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.savefig(f\"imgs/time_series_noisy_test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_histories = {\n",
    "    (sigma, best_configs[sigma]): histories[best_configs[sigma]]\n",
    "    for sigma, histories in sigma_histories.items()\n",
    "}\n",
    "\n",
    "for (sigma, config), history in best_histories.items():\n",
    "    best_test = history[(\"test_loss\", \"mean\")][-1]\n",
    "\n",
    "    print(f\"{config} model performance on test set (SD = {sigma}): {best_test:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1e-4, 1e-3, 5e-3, 1e-2]\n",
    "lambda_histories = {}\n",
    "models = {}\n",
    "\n",
    "iterator = tqdm(best_configs.items())\n",
    "\n",
    "for (sigma, config) in iterator:\n",
    "    iterator.set_description(f\"Running with sigma = {sigma}\")\n",
    "    Xn_train = X_train + np.random.normal(loc = 0, scale=sigma, size=X_train.shape)\n",
    "    Xn_val = X_val\n",
    "    Xn_test = X_test\n",
    "\n",
    "    yn_train = y_train + np.random.normal(loc=0, scale=sigma, size=y_train.shape)\n",
    "    yn_val = y_val\n",
    "    yn_test = y_test\n",
    "\n",
    "    lambda_histories[sigma] = parameter_search(\n",
    "        Xn_train,\n",
    "        yn_train,\n",
    "        Xn_val,\n",
    "        yn_val,\n",
    "        Xn_test,\n",
    "        yn_test,\n",
    "        layers_config=config,\n",
    "        lambdas=lambdas,\n",
    "        n_epochs=200,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma, histories in lambda_histories.items():\n",
    "    fig, ax = plot_training_histories(histories, type=\"lambda\")\n",
    "    plt.title(f\"Training History for $\\\\sigma = {sigma}$\")\n",
    "    plt.savefig(f\"imgs/layers_selection_{sigma}_noisy_lambda.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [1e-4, 1e-3, 5e-3, 1e-2]\n",
    "best_configs = {0.05: (4, 6), 0.15: (4, 9)}\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 10))\n",
    "\n",
    "fig.suptitle(\"Actual vs Predicted Values\")\n",
    "\n",
    "for i, (sigma, config) in enumerate(best_configs.items()):\n",
    "    for j, lmbda in enumerate(lambdas):\n",
    "        model = TimeSeriesMLP(\n",
    "            hidden_nodes=config, n_epochs=200, early_stopping=False, lmbda=lmbda\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train + np.random.normal(loc=0, scale=sigma, size=X_train.shape),\n",
    "            y_train + np.random.normal(loc=0, scale=sigma, size=y_train.shape),\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "        data = {\n",
    "            \"t\": steps[-200:] + 5,\n",
    "            \"Truth\": y_test,\n",
    "            f\"{config}\": model.predict(X_test).flatten(),\n",
    "        }\n",
    "        data = pd.DataFrame(data)\n",
    "        data = pd.melt(data, [\"t\"])\n",
    "        data.columns = [\"t\", \"Model\", \"Value\"]\n",
    "\n",
    "        axs[i][j] = sns.lineplot(data, x=\"t\", y=\"Value\", hue=\"Model\", ax=axs[i][j])\n",
    "\n",
    "        axs[i][j].set_title(f\"$\\\\sigma = {sigma}$, $\\\\lambda = {lmbda}$\")\n",
    "        axs[i][j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"imgs/time_series_noisy_test_lambda.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import TimeSeriesMLP\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 10))\n",
    "\n",
    "fig.suptitle(\"Weight Distribution for each Model\")\n",
    "\n",
    "for i, ((sigma, config), input, output) in enumerate(zip(best_configs.items(), noised_inputs, noised_outputs)):\n",
    "    for j, lmbda in enumerate(lambdas):\n",
    "        model = TimeSeriesMLP(hidden_nodes=config, n_epochs=200, early_stopping=False, lmbda=lmbda)\n",
    "        model.fit(input[:-280], output[:-280], input[-280:-200], output[-280:-200])\n",
    "        \n",
    "        data = []\n",
    "        for w in model.get_weights():\n",
    "            data.extend(w.flatten())\n",
    "\n",
    "        axs[i][j] = sns.histplot(data, ax=axs[i][j])\n",
    "\n",
    "        axs[i][j].set_title(f'$\\\\sigma = {sigma}$, $\\\\lambda = {lmbda}$')\n",
    "        axs[i][j].set_xlabel(\"Weight Value\")\n",
    "        axs[i][j].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./imgs/weights_distribution.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
