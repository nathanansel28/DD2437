from typing import List, Tuple

import matplotlib.pyplot as plt
import numpy as np


def generate_dataset(
    n_samples: int = 100,
    means: np.ndarray = np.array([[4.0, -2.0], [-2.0, 3.0]]),
    standard_deviations: List[float] = [3.5, 5.0],
    seed: int = 20250122,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Generates a synthetic dataset with two classes,
    where each class follows a Gaussian-like distribution.

    Parameters:
    ----------
    n_samples : int, optional
        The number of samples to generate per class. Default is 100.
    means : np.ndarray, optional
        A 2D array where each row represents the mean (center) of a class
        in 2D space. Default is np.array([[4.0, -2.0], [-2.0, 3.0]]).
    standard_deviations : List[float], optional
        A list of standard deviations for each class. Each standard deviation
        determines the spread of the points around the corresponding mean.
        Default is [3.5, 5.0].
    seed : int, optional
        Random seed for reproducibility. Default is 20250122.

    Returns:
    -------
    Tuple[np.ndarray, np.ndarray]
        A tuple containing:
        - data: A 2D NumPy array of shape (n_samples * num_classes, 2), where
          each row is a point in 2D space.
        - labels: A 1D NumPy array of shape (n_samples * num_classes,),
          where each element is the class label (0, 1, ...).

    Raises:
    ------
    AssertionError
        If the number of class means does not match the number of standard
        deviations or if `means` is not a 2D array.

    Notes:
    -----
    - The data points for each class are generated by adding Gaussian noise
      to the specified class mean, scaled by the corresponding standard
      deviation.
    - The generated data and labels are shuffled to ensure randomness.
    """

    # Ensure two-dimensionality
    assert means.ndim == 2
    # Ensure same amount of classes
    assert len(means) == len(standard_deviations)

    # Initialise data points and labels
    data = []
    labels = []
    generator = np.random.default_rng(seed=seed)

    for i in range(len(means)):
        # Generate random points with specific mean and standard deviation
        points = generator.random((2, n_samples)) * standard_deviations[i] + means[
            i
        ].reshape(2, 1)
        # Add points to data
        data.append(points)
        # Add same label for the generated points
        labels.append(np.full((n_samples), i, dtype=int))

    # Concatenate all data points and labels
    data = np.hstack(data)
    labels = np.hstack(labels)

    # Shuffle data points and labels with same permutation
    indexes = generator.permutation(n_samples * len(means))
    data = data[:, indexes]
    labels = labels[indexes]

    return data, labels


def plot_decision_boundary(
    weights: np.ndarray, data: np.ndarray, labels: np.ndarray, title: str
):
    """
    Plots a 2D dataset with its corresponding decision boundary.

    Parameters:
    ----------
    weights : np.ndarray
        A 1D NumPy array of shape (3,) or (,3) containing the weights of the decision
        boundary equation: [w1, w2, b], where:
        - w1 and w2 are the coefficients for the features X1 and X2.
        - b is the bias term.
    data : np.ndarray
        A 2D NumPy array of shape (2, n_samples) containing the dataset. Each
        column represents a data point, where the first row contains the X1
        coordinates, and the second row contains the X2 coordinates.
    labels : np.ndarray
        A 1D NumPy array of shape (n_samples,) containing the class labels
        (0 or 1) for each data point.
    title : str
        The title of the plot.

    Returns:
    -------
    None
        This function does not return anything. It displays the plot.

    Notes:
    -----
    - The decision boundary is defined by the equation: `w1 * X1 + w2 * X2 + b = 0`.
      If w2 is 0, a vertical line is plotted at `X1 = -b / w1`.
    - The dataset points are colored based on their labels:
        - "Class A" (label 0) is displayed in blue.
        - "Class B" (label 1) is displayed in orange.
    - The plot includes axes with gridlines for better visualization.
    """
    # Unpack weights (w1, w2, b)
    w1, w2, b = weights

    # Generate X1 values (spanning the range of the dataset)
    x1_range = np.linspace(data[0, :].min() - 1, data[0, :].max() + 1, 100)

    # Calculate x2 values using the decision boundary equation
    if w2 != 0:  # Avoid division by zero
        x2_range = -(w1 * x1_range + b) / w2
    else:
        x2_range = np.full_like(x1_range, -b / w1)  # Vertical line if w2 == 0

    # Plot the data points
    plt.scatter(
        data[0, labels != 1],
        data[1, labels != 1],
        label="Class A",
        alpha=0.7,
        color="blue",
    )
    plt.scatter(
        data[0, labels == 1],
        data[
            1,
            labels == 1,
        ],
        label="Class B",
        alpha=0.7,
        color="orange",
    )

    # Plot the decision boundary
    plt.plot(x1_range, x2_range, "k--", label="Decision boundary")

    # Customize the plot
    plt.axhline(0, color="gray", linestyle="--", linewidth=0.5)
    plt.axvline(0, color="gray", linestyle="--", linewidth=0.5)
    plt.xlabel("X1")
    plt.ylabel("X2")
    plt.legend()
    plt.title(title)
    plt.tight_layout()
    plt.show()


def add_bias(X: np.ndarray) -> np.ndarray:
    """
    Adds a bias term to the input data by appending a row of ones.

    Parameters:
    ----------
    X : np.ndarray
        A 2D NumPy array of shape (n_features, n_samples), where each column
        represents a data point.

    Returns:
    -------
    np.ndarray
        A 2D NumPy array of shape (n_features + 1, n_samples) with an
        additional bias row of ones.
    """
    return np.vstack((X, np.ones((1, X.shape[1]))))


class PerceptronClassifier:
    def __init__(self) -> None:
        """
        Initializes the PerceptronClassifier with no weights. The weights
        are initialized during training using the `fit` method.
        """
        self.weights: np.ndarray = None

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        learn_rate: float = 0.25,
        epochs: int = 10,
        batch: bool = False,
    ) -> None:
        """
        Trains the perceptron model using the provided training data and labels.

        Parameters:
        ----------
        X : np.ndarray
            A 2D NumPy array of shape (n_features, n_samples) containing the
            training data. Each column represents a data point.
        y : np.ndarray
            A 1D or 2D NumPy array of shape (n_samples,) or (n_samples, 1)
            containing the class labels for each data point. For binary classification,
            labels should be 0 or 1.
        learn_rate : float, optional
            The learning rate for weight updates. Default is 0.25.
        epochs : int, optional
            The number of passes over the training data. Default is 10.
        batch : bool, optional
            If True, updates are accumulated over all samples in an epoch before being applied (batch learning).
            If False, weights are updated for each sample individually (online learning). Default is False.

        Returns:
        -------
        None
            Trains the model and updates the `weights` attribute in place.

        Notes:
        -----
        - Weights are initialized randomly in the range [-0.05, 0.05].
        - For binary classification, `weights` will have shape (n_features + 1, 1).
        - For multi-class classification, `weights` will have shape (n_features + 1, n_classes).
        """
        inputs = add_bias(X)
        labels = y = (
            y.reshape(-1, 1) if y.ndim == 1 else y
        )  # Ensure y is (1, n_samples)

        rndg = np.random.default_rng(seed=20250122)
        # Initialise weight randomly with mean 0.05 and standard deviation 0.05
        num_classes = len(np.unique(y))
        self.weights = (
            rndg.random((X.shape[0] + 1, 1 if num_classes == 2 else num_classes)) * 0.1
            - 0.05
        )
        # Prepare delta accumulator in case of batch learning
        accumulator = np.zeros_like(self.weights)

        for _ in range(epochs):
            # Get predictions
            preds = self.predict(X)
            # Compute delta weights
            delta = learn_rate * np.dot(inputs, labels - preds)

            if batch:
                accumulator += delta
            else:
                self.weights += delta

        if batch:
            self.weights += accumulator

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predicts class labels for the given input data.

        Parameters:
        ----------
        X : np.ndarray
            A 2D NumPy array of shape (n_features, n_samples) containing the
            input data. Each column represents a data point.

        Returns:
        -------
        np.ndarray
            A 1D NumPy array of shape (n_samples,) for multi-class classification,
            or a 2D array of shape (n_samples, 1) for binary classification.
            Binary predictions are 0 or 1.

        Notes:
        -----
        - For binary classification, activations are thresholded at 0 to predict labels.
        - For multi-class classification, the predicted label corresponds to the
          index of the maximum activation.
        """
        inputs = add_bias(X)

        # Compute activations
        activations = np.dot(np.transpose(self.weights), inputs)
        # Threshold the activations
        if self.weights.shape[1] == 1:  # Binary classification
            return np.where(activations > 0, 1, 0).reshape((-1, 1))
        return np.argmax(activations, axis=0)  # Multi-class classification


class DeltaRuleClassifier:
    def __init__(self) -> None:
        """
        Initializes the DeltaRuleClassifier with no weights. Weights are initialized
        during training using the `fit` method.
        """
        self.weights = None

    def fit(
        self,
        X: np.ndarray,
        y: np.ndarray,
        learn_rate: float = 0.001,
        epochs: int = 20,
        batch: bool = True,
    ) -> None:
        """
        Trains the classifier on the input data and labels using gradient descent.

        Parameters:
        ----------
        X : np.ndarray
            A 2D NumPy array of shape (n_features, n_samples) containing the training data.
            Each column is a data point.
        y : np.ndarray
            A 1D or 2D NumPy array of shape (n_samples,) or (n_samples, n_classes)
            containing the true labels for each data point. Binary labels should be
            represented as 1 and -1 for binary classification.
        learn_rate : float, optional
            The learning rate for weight updates. Default is 0.001.
        epochs : int, optional
            The number of iterations over the training data. Default is 20.
        batch : bool, optional
            If True, updates are accumulated over all samples before being applied to
            the weights (batch learning). If False, weights are updated for each sample
            individually (online learning). Default is True.

        Returns:
        -------
        None
            The trained weights are stored in the `weights` attribute.

        Notes:
        -----
        - The weights are initialized randomly in the range [-0.05, 0.05].
        - For binary classification, `weights` will have shape (n_features + 1, 1).
        - For multi-class classification, `weights` will have shape
          (n_features + 1, n_classes).
        """
        inputs = add_bias(X)
        labels = y = (
            y.reshape(-1, 1) if y.ndim == 1 else y
        )  # Ensure y is (1, n_samples)

        rndg = np.random.default_rng(seed=20250122)
        # Initialise weight randomly with mean 0.05 and standard deviation 0.05
        num_classes = len(np.unique(y))
        self.weights = (
            rndg.random((X.shape[0] + 1, 1 if num_classes == 2 else num_classes)) * 0.1
            - 0.05
        )
        # Prepare delta accumulator in case of batch learning
        accumulator = np.zeros_like(self.weights)

        for _ in range(epochs):
            # Compute error
            error = labels - np.dot(np.transpose(self.weights), inputs).reshape((-1, 1))
            delta = learn_rate * np.dot(inputs, error)

            if batch:
                accumulator += delta
            else:
                self.weights += delta

        if batch:
            self.weights += delta

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predicts class labels for the input data.

        Parameters:
        ----------
        X : np.ndarray
            A 2D NumPy array of shape (n_features, n_samples) containing the input data.
            Each column is a data point.

        Returns:
        -------
        np.ndarray
            A 2D NumPy array of shape (n_samples, 1) for binary classification,
            containing the predicted labels (1 or -1).
            For multi-class classification, returns a 1D NumPy array of shape (n_samples,)
            containing the predicted class indices (0, 1, ..., n_classes-1).

        Notes:
        -----
        - For binary classification, activations are thresholded at 0.
        - For multi-class classification, the predicted class corresponds to the index
          of the maximum activation for each sample.
        """
        inputs = add_bias(X)

        # Compute activations
        activations = np.dot(np.transpose(self.weights), inputs)
        # Threshold the activations
        if self.weights.shape[1] == 1:  # Binary classification
            return np.where(activations > 0, 1, -1).reshape((-1, 1))
        return np.argmax(activations, axis=0)  # Multi-class classification
